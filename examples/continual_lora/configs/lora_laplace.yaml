# File dirs
logs_dir: &logs_path "./examples/runs/lora/"

experiment_name: "lora_laplace"
num_tasks: 20
lambda_param: 100
lr: 1e-4
accumulate_gradients_every: 5
early_stopping: false

# Model
model_config: &model_params
  pretrained_model_name_or_path: "meta-llama/Llama-2-7b-hf"
  first_prior_sd: 1e4
  ignore_first: 2048

  #LoRA
  lora_config: &lora_params
    target_modules: "last_layer"
    r: 8
    alpha: 32
    dropout: 0.

# Dataset
dataset_path: "./examples/continual_lora/data/pg19-20.json"
train_batch_size: 2
laplace_batch_size: 1
drop_last: false
train_proportion: 0.85
shuffle: false
num_workers: 11
tokenizer_pretrained_model_name_or_path: "meta-llama/Llama-2-7b-hf"
stride_length: 4096
stride_overlap: 2048
